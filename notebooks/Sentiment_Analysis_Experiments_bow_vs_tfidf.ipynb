{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42c644f7f7824eaf8951b8a9bbfc7711": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_64e6507335cd4b958c68eacc719fe6b8",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32mтаж\u001b[0m Waiting for authorization\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">таж</span> Waiting for authorization\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "64e6507335cd4b958c68eacc719fe6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow dagshub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjXm-YiFyYUd",
        "outputId": "485da1cf-b668-418a-b4d8-f4e8fa9fed46"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.21.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting dagshub\n",
            "  Downloading dagshub-0.5.9-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mlflow-skinny==2.21.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.21.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.14.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.39)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading databricks_sdk-0.47.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (1.31.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (2.10.6)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.21.0->mlflow) (4.12.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting appdirs>=1.4.4 (from dagshub)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (13.9.4)\n",
            "Collecting dacite~=1.6.0 (from dagshub)\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (9.0.0)\n",
            "Collecting gql[requests] (from dagshub)\n",
            "  Downloading gql-3.5.2-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting dataclasses-json (from dagshub)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting treelib>=1.6.4 (from dagshub)\n",
            "  Downloading treelib-1.7.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pathvalidate>=3.0.0 (from dagshub)\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.8.2)\n",
            "Collecting boto3 (from dagshub)\n",
            "  Downloading boto3-1.37.19-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting semver (from dagshub)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting dagshub-annotation-converter>=0.1.5 (from dagshub)\n",
            "  Downloading dagshub_annotation_converter-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.1.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.3.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.1.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow) (4.0.12)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->dagshub) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.18.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Collecting botocore<1.38.0,>=1.37.19 (from boto3->dagshub)\n",
            "  Downloading botocore-1.37.19-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->dagshub)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->dagshub)\n",
            "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->dagshub)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->dagshub)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.18.3)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow) (2.38.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.21.0->mlflow)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow) (0.52b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.0->mlflow) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.0->mlflow) (3.4.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.0->mlflow) (1.17.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.21.0-py3-none-any.whl (28.2 MB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.21.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dagshub-0.5.9-py3-none-any.whl (260 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading dagshub_annotation_converter-0.1.7-py3-none-any.whl (33 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading treelib-1.7.1-py3-none-any.whl (19 kB)\n",
            "Downloading boto3-1.37.19-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading botocore-1.37.19-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.47.0-py3-none-any.whl (681 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m681.0/681.0 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gql-3.5.2-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, uvicorn, treelib, semver, pathvalidate, mypy-extensions, marshmallow, jmespath, gunicorn, graphql-core, dacite, backoff, typing-inspect, starlette, graphql-relay, gql, docker, botocore, alembic, s3transfer, graphene, fastapi, dataclasses-json, databricks-sdk, dagshub-annotation-converter, boto3, mlflow-skinny, dagshub, mlflow\n",
            "Successfully installed alembic-1.15.1 appdirs-1.4.4 backoff-2.2.1 boto3-1.37.19 botocore-1.37.19 dacite-1.6.0 dagshub-0.5.9 dagshub-annotation-converter-0.1.7 databricks-sdk-0.47.0 dataclasses-json-0.6.7 docker-7.1.0 fastapi-0.115.12 gql-3.5.2 graphene-3.4.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 marshmallow-3.26.1 mlflow-2.21.0 mlflow-skinny-2.21.0 mypy-extensions-1.0.0 pathvalidate-3.2.3 s3transfer-0.11.4 semver-3.0.4 starlette-0.46.1 treelib-1.7.1 typing-inspect-0.9.0 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import setuptools\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import time\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import dagshub\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import scipy.sparse\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "kT4niO0dx40Y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== CONFIGURATION ==========================\n",
        "CONFIG = {\n",
        "    \"data_path\": \"data.csv\",          # Ensure import data\n",
        "    \"test_size\": 0.2,\n",
        "    \"mlflow_tracking_uri\": \"https://dagshub.com/satvikk/Capstone.mlflow\",\n",
        "    \"dagshub_repo_owner\": \"satvikk\",\n",
        "    \"dagshub_repo_name\": \"Capstone\",\n",
        "    \"experiment_name\": \"Bow vs TfIdf\"\n",
        "}"
      ],
      "metadata": {
        "id": "WObOeGRty3A_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== SETUP MLflow & DAGSHUB ==========================\n",
        "mlflow.set_tracking_uri(CONFIG[\"mlflow_tracking_uri\"])\n",
        "dagshub.init(repo_owner=CONFIG[\"dagshub_repo_owner\"], repo_name=CONFIG[\"dagshub_repo_name\"], mlflow=True)\n",
        "mlflow.set_experiment(CONFIG[\"experiment_name\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "42c644f7f7824eaf8951b8a9bbfc7711",
            "64e6507335cd4b958c68eacc719fe6b8"
          ]
        },
        "id": "YqI_QJHIzHQf",
        "outputId": "ccd398aa-19ce-4c82-81ce-8940599fea93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                       \u001b[1mтЭЧтЭЧтЭЧ AUTHORIZATION REQUIRED тЭЧтЭЧтЭЧ\u001b[0m                                        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">тЭЧтЭЧтЭЧ AUTHORIZATION REQUIRED тЭЧтЭЧтЭЧ</span>                                        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42c644f7f7824eaf8951b8a9bbfc7711"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=e9922956-d249-4b59-9b96-1ea643c34893&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=c1f39ce48f5fd95067619e1e4e92a56c550031899eb7f7cc52283f7025128aad\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accessing as satvikk\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as satvikk\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"satvikk/Capstone\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"satvikk/Capstone\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository satvikk/Capstone initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository satvikk/Capstone initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/03/25 05:36:22 INFO mlflow.tracking.fluent: Experiment with name 'Bow vs TfIdf' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/2557364f8ab844e0853cd751db83332a', creation_time=1742880982231, experiment_id='1', last_update_time=1742880982231, lifecycle_stage='active', name='Bow vs TfIdf', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== TEXT PREPROCESSING ==========================\n",
        "def lemmatization(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "def remove_stop_words(text):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    return \" \".join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "def removing_numbers(text):\n",
        "    return ''.join([char for char in text if not char.isdigit()])\n",
        "\n",
        "def lower_case(text):\n",
        "    return text.lower()\n",
        "\n",
        "def removing_punctuations(text):\n",
        "    return re.sub(f\"[{re.escape(string.punctuation)}]\", ' ', text)\n",
        "\n",
        "def removing_urls(text):\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def normalize_text(df):\n",
        "    try:\n",
        "        df['review'] = df['review'].apply(lower_case)\n",
        "        df['review'] = df['review'].apply(remove_stop_words)\n",
        "        df['review'] = df['review'].apply(removing_numbers)\n",
        "        df['review'] = df['review'].apply(removing_punctuations)\n",
        "        df['review'] = df['review'].apply(removing_urls)\n",
        "        df['review'] = df['review'].apply(lemmatization)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error during text normalization: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "X-7avVAgzXTG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== LOAD & PREPROCESS DATA ==========================\n",
        "def load_data(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = normalize_text(df)\n",
        "        df = df[df['sentiment'].isin(['positive', 'negative'])]\n",
        "        df['sentiment'] = df['sentiment'].replace({'negative': 0, 'positive': 1}).infer_objects(copy=False)\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "0s43oqGJzbg6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== FEATURE ENGINEERING ==========================\n",
        "VECTORIZERS = {\n",
        "    'BoW': CountVectorizer(),\n",
        "    'TF-IDF': TfidfVectorizer()\n",
        "}\n",
        "\n",
        "ALGORITHMS = {\n",
        "    'LogisticRegression': LogisticRegression(),\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'GradientBoosting': GradientBoostingClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "Bm4oggNczfRo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================== TRAIN & EVALUATE MODELS ==========================\n",
        "def train_and_evaluate(df):\n",
        "    with mlflow.start_run(run_name=\"Experiments with RS Zero\") as parent_run:\n",
        "        start_time = time.time()\n",
        "        for algo_name, algorithm in ALGORITHMS.items():\n",
        "            for vec_name, vectorizer in VECTORIZERS.items():\n",
        "                with mlflow.start_run(run_name=f\"{algo_name} with {vec_name}\", nested=True) as child_run:\n",
        "                    try:\n",
        "                        # Feature extraction\n",
        "                        X = vectorizer.fit_transform(df['review'])\n",
        "                        y = df['sentiment']\n",
        "                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=CONFIG[\"test_size\"], random_state=42)\n",
        "\n",
        "                        # Log preprocessing parameters\n",
        "                        mlflow.log_params({\n",
        "                            \"vectorizer\": vec_name,\n",
        "                            \"algorithm\": algo_name,\n",
        "                            \"test_size\": CONFIG[\"test_size\"]\n",
        "                        })\n",
        "\n",
        "                        # Train model\n",
        "                        model = algorithm\n",
        "                        model.fit(X_train, y_train)\n",
        "\n",
        "                        # Log model parameters\n",
        "                        log_model_params(algo_name, model)\n",
        "\n",
        "                        # Evaluate model\n",
        "                        y_pred = model.predict(X_test)\n",
        "                        metrics = {\n",
        "                            \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "                            \"precision\": precision_score(y_test, y_pred),\n",
        "                            \"recall\": recall_score(y_test, y_pred),\n",
        "                            \"f1_score\": f1_score(y_test, y_pred)\n",
        "                        }\n",
        "                        mlflow.log_metrics(metrics)\n",
        "\n",
        "                        # Log model\n",
        "                        # mlflow.sklearn.log_model(model, \"model\")\n",
        "                        input_example = X_test[:5] if not scipy.sparse.issparse(X_test) else X_test[:5].toarray()\n",
        "                        mlflow.sklearn.log_model(model, \"model\", input_example=input_example)\n",
        "\n",
        "                        # Print results for verification\n",
        "                        print(f\"\\nAlgorithm: {algo_name}, Vectorizer: {vec_name}\")\n",
        "                        print(f\"Metrics: {metrics}\")\n",
        "                        # Log execution time\n",
        "                        end_time = time.time()\n",
        "                        print(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error in training {algo_name} with {vec_name}: {e}\")\n",
        "                        mlflow.log_param(\"error\", str(e))\n",
        "\n",
        "def log_model_params(algo_name, model):\n",
        "    \"\"\"Logs hyperparameters of the trained model to MLflow.\"\"\"\n",
        "    params_to_log = {}\n",
        "    if algo_name == 'LogisticRegression':\n",
        "        params_to_log[\"C\"] = model.C\n",
        "    elif algo_name == 'MultinomialNB':\n",
        "        params_to_log[\"alpha\"] = model.alpha\n",
        "    elif algo_name == 'XGBoost':\n",
        "        params_to_log[\"n_estimators\"] = model.n_estimators\n",
        "        params_to_log[\"learning_rate\"] = model.learning_rate\n",
        "    elif algo_name == 'RandomForest':\n",
        "        params_to_log[\"n_estimators\"] = model.n_estimators\n",
        "        params_to_log[\"max_depth\"] = model.max_depth\n",
        "    elif algo_name == 'GradientBoosting':\n",
        "        params_to_log[\"n_estimators\"] = model.n_estimators\n",
        "        params_to_log[\"learning_rate\"] = model.learning_rate\n",
        "        params_to_log[\"max_depth\"] = model.max_depth\n",
        "\n",
        "    mlflow.log_params(params_to_log)"
      ],
      "metadata": {
        "id": "OdzAVl5Mzosr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze8oQwdBz6Od",
        "outputId": "d39c4126-4d91-4efa-bcd5-2ad4d04376a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5JjscLNxx6l",
        "outputId": "cfd6675a-7add-46ed-e805-77d5ea2ff3bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Algorithm: LogisticRegression, Vectorizer: BoW\n",
            "Metrics: {'accuracy': 0.7, 'precision': 0.660377358490566, 'recall': 0.7446808510638298, 'f1_score': 0.7}\n",
            "Model training and logging completed in 23.37 seconds.\n",
            "ЁЯПГ View run LogisticRegression with BoW at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/397c747f37454541896e22ee0ea965ae\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: LogisticRegression, Vectorizer: TF-IDF\n",
            "Metrics: {'accuracy': 0.73, 'precision': 0.7631578947368421, 'recall': 0.6170212765957447, 'f1_score': 0.6823529411764706}\n",
            "Model training and logging completed in 33.36 seconds.\n",
            "ЁЯПГ View run LogisticRegression with TF-IDF at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/2962c4c24c134164828186a3e5c9a380\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: MultinomialNB, Vectorizer: BoW\n",
            "Metrics: {'accuracy': 0.79, 'precision': 0.8095238095238095, 'recall': 0.723404255319149, 'f1_score': 0.7640449438202247}\n",
            "Model training and logging completed in 46.89 seconds.\n",
            "ЁЯПГ View run MultinomialNB with BoW at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/e4ee8a31837548baa122cc9b6183ba8d\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: MultinomialNB, Vectorizer: TF-IDF\n",
            "Metrics: {'accuracy': 0.6, 'precision': 0.8181818181818182, 'recall': 0.19148936170212766, 'f1_score': 0.3103448275862069}\n",
            "Model training and logging completed in 137.56 seconds.\n",
            "ЁЯПГ View run MultinomialNB with TF-IDF at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/d4c41be732b442eeb237aaff2df34ef9\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: XGBoost, Vectorizer: BoW\n",
            "Metrics: {'accuracy': 0.74, 'precision': 0.7333333333333333, 'recall': 0.7021276595744681, 'f1_score': 0.717391304347826}\n",
            "Model training and logging completed in 149.13 seconds.\n",
            "ЁЯПГ View run XGBoost with BoW at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/d1bf6dcc875a4d9a8f27dd3ab278a752\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: XGBoost, Vectorizer: TF-IDF\n",
            "Metrics: {'accuracy': 0.67, 'precision': 0.6346153846153846, 'recall': 0.7021276595744681, 'f1_score': 0.6666666666666666}\n",
            "Model training and logging completed in 160.62 seconds.\n",
            "ЁЯПГ View run XGBoost with TF-IDF at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/a7c428cd013245e595ffc31bc4ccd360\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: RandomForest, Vectorizer: BoW\n",
            "Metrics: {'accuracy': 0.74, 'precision': 0.7560975609756098, 'recall': 0.6595744680851063, 'f1_score': 0.7045454545454546}\n",
            "Model training and logging completed in 173.91 seconds.\n",
            "ЁЯПГ View run RandomForest with BoW at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/351f55444763429eba1161618e7b8bad\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: RandomForest, Vectorizer: TF-IDF\n",
            "Metrics: {'accuracy': 0.65, 'precision': 0.65, 'recall': 0.5531914893617021, 'f1_score': 0.5977011494252874}\n",
            "Model training and logging completed in 189.78 seconds.\n",
            "ЁЯПГ View run RandomForest with TF-IDF at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/f3b152ac42a041cfa3d0493f1324aed2\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: GradientBoosting, Vectorizer: BoW\n",
            "Metrics: {'accuracy': 0.67, 'precision': 0.6346153846153846, 'recall': 0.7021276595744681, 'f1_score': 0.6666666666666666}\n",
            "Model training and logging completed in 204.82 seconds.\n",
            "ЁЯПГ View run GradientBoosting with BoW at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/59b6977368e94e5bb9f625f05dd33d5e\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "\n",
            "Algorithm: GradientBoosting, Vectorizer: TF-IDF\n",
            "Metrics: {'accuracy': 0.71, 'precision': 0.6666666666666666, 'recall': 0.7659574468085106, 'f1_score': 0.7128712871287128}\n",
            "Model training and logging completed in 219.43 seconds.\n",
            "ЁЯПГ View run GradientBoosting with TF-IDF at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/01c19bd8148c429aac9e15b1abf90a86\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n",
            "ЁЯПГ View run Experiments with RS Zero at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1/runs/b0b8a0d1a5b9413ebd20c0f6b1d6e16c\n",
            "ЁЯзк View experiment at: https://dagshub.com/satvikk/Capstone.mlflow/#/experiments/1\n"
          ]
        }
      ],
      "source": [
        "# ========================== EXECUTION ==========================\n",
        "if __name__ == \"__main__\":\n",
        "    df = load_data(CONFIG[\"data_path\"])\n",
        "    train_and_evaluate(df)\n"
      ]
    }
  ]
}